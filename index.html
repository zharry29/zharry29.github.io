<!DOCTYPE html>
<html>

<head>
  <title>Li "Harry" Zhang</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="image/favicon.png" sizes="16x16">
  <link rel="stylesheet" href="./w3.css">
  <link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <style>
  html,
  body,
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    font-family: "Roboto", sans-serif
  }
  
  .video-container {
    position: relative;
    padding-bottom: 56.25%;
    padding-top: 0px;
    height: 0;
    overflow: hidden;
  }
  
  img {
    max-width: 100%;
    max-height: 100%;
  }
  
  .video-container iframe,
  .video-container object,
  .video-container embed {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
  
  .tooltip {
    position: relative;
    display: inline-block;
    border-bottom: 1px dotted black;
  }
  
  .tooltip .tooltiptext {
    visibility: hidden;
    width: 140px;
    background-color: black;
    color: #fff;
    text-align: center;
    border-radius: 6px;
    padding: 5px 0;
    /* Position the tooltip */
    position: absolute;
    z-index: 1;
  }
  
  .tooltip:hover .tooltiptext {
    visibility: visible;
  }
  
  .hidden {
    display: none;
  }
  
  .button {
    background-color: Transparent;
    background-repeat: no-repeat;
    border: none;
    cursor: pointer;
    overflow: hidden;
    outline: none;
  }
  
  a {
    color: #9900cc;
    text-decoration: none;
  }
  
  .fab {
    position: relative;
    top: 3px;
  }
  
  .help {
    cursor: help;
  }
  </style>
  <!-- Place your kit's code here -->
  <script src="https://kit.fontawesome.com/e86b39c03c.js" crossorigin="anonymous"></script>
  <script>
  function toggleMoreResearch() {
    var x = document.getElementById("more_research");
    var y = document.getElementById("show_more_button");
    var z = document.getElementById("show_less_button");
    x.style.display = "block";
    y.style.display = "none";
    z.style.display = "block";
  }

  function toggleCollapseResearch() {
    var x = document.getElementById("more_research");
    var y = document.getElementById("show_more_button");
    var z = document.getElementById("show_less_button");
    x.style.display = "none";
    y.style.display = "block";
    z.style.display = "none";
  }
  function toggleMorePublications() {
    var x = document.getElementById("more_publications");
    var y = document.getElementById("show_more_button_pub");
    var z = document.getElementById("show_less_button_pub");
    x.style.display = "block";
    y.style.display = "none";
    z.style.display = "block";
  }

  function toggleCollapsePublications() {
    var x = document.getElementById("more_publications");
    var y = document.getElementById("show_more_button_pub");
    var z = document.getElementById("show_less_button_pub");
    x.style.display = "none";
    y.style.display = "block";
    z.style.display = "none";
  }

  function toggle(bib) {
    var x = document.getElementById(bib);
    if(x.style.display === "block") {
      x.style.display = "none";
    } else {
      x.style.display = "block";
    }
  }
  </script>
</head>

<body class="w3-light-grey">
  <!-- Page Container -->
  <div class="w3-content w3-margin-top" style="max-width:1400px;">
    <!-- The Grid -->
    <div class="w3-row-padding">
      <!-- Left Column -->
      <div class="w3-third">
        <div class="w3-white w3-text-grey w3-card-4">
          <div class="w3-display-container">
            <!--
          <img src="avatar.jpg" style="width:100%" alt="Avatar">
    --><img src="image/guitar.jpg" style="width:100%" alt="Avatar"> </div>
          <center>
            <h2><font face="georgia"> Li "Harry" Zhang &nbsp;</font><b>张力 </b></h2></center>
          <div class="w3-container">
            <hr>
            <p class="w3-large w3-text-theme"><b><i class="fa fa-user fa-fw w3-margin-right w3-text-purple"></i>About Me</b></p>
            <p><font color='black'>
              I am a third-year PhD student researcher focusing on <b>Natural Language Processing</b>, mentored by <a href="http://www.cis.upenn.edu/~ccb/" target="_blank">Prof. Chris Callison-Burch</a> at the University of Pennsylvania. I was an undergraduate at the University of Michigan in 2018, previously mentored by <a href="https://web.eecs.umich.edu/~mihalcea/" target="_blank">Prof. Rada Mihalcea</a> and <a href="http://www.cs.yale.edu/homes/radev/" target="_blank">Prof. Dragomir Radev</a>. I'm also a drummer, musician, producer, and video creator. 
              <br>
              <br>
              My area of focus is on <b>procedures</b>, like recipes or instructions. I teach machines to understand and reason about them. 
            </font></p>
            <a href="docs/CV.pdf" target="_blank"><span class="w3-tag w3-purple w3-round w3-hover-opacity">CV</span></a> &nbsp; <a href="https://space.bilibili.com/483770554" target="_blank"><img src="image/1200px-Bilibili_Logo_Blue.svg.png" alt="bilibili" width="50"></a> &nbsp; <a href="https://www.youtube.com/c/HazStudio" target="_blank"><i class="fab fa-youtube w3-xxlarge w3-hover-opacity"></i></a> &nbsp; <a href="https://open.spotify.com/artist/6ntpoMsRdS6WWUiuGjvcsf" target="_blank"><i class="fab fa-spotify w3-xxlarge w3-hover-opacity"></i></a> &nbsp; <a href="https://music.apple.com/us/artist/haz-studio/1565038720" target="_blank"><i class="fab fa-apple w3-xxlarge w3-hover-opacity"></i></a> &nbsp; <a href="https://music.amazon.com/artists/B093NPZGC5/haz-studio" target="_blank"><i class="fab fa-amazon w3-xxlarge w3-hover-opacity"></i></a> &nbsp; <a href="https://www.facebook.com/gyczzl997" target="_blank"><i class="fab fa-facebook-square w3-xxlarge w3-hover-opacity"></i></a> &nbsp; <a href="https://twitter.com/liharryzhang" target="_blank"><i class="fab fa-twitter-square w3-xxlarge w3-hover-opacity"></i></a> &nbsp; <a href="https://www.linkedin.com/in/hazrael" target="_blank"><i class="fab fa-linkedin w3-xxlarge w3-hover-opacity"></i></a> <a href="https://www.semanticscholar.org/author/72436283" target="_blank"><button class='button'><span class="w3-tag w3-purple w3-round w3-hover-opacity">Semantic Scholar</span></button></a> <a href="https://dblp.org/pid/89/5992-39.html" target="_blank"><button class='button'><span class="w3-tag w3-purple w3-round w3-hover-opacity">DBLP</span></button></a> <a href="https://scholar.google.com/citations?user=_VLzlBIAAAAJ" target="_blank"><button class='button'><span class="w3-tag w3-purple w3-round w3-hover-opacity">Google Scholar</span></button></a> <a href="https://openreview.net/profile?id=~Li_Zhang22" target="_blank"><button class='button'><span class="w3-tag w3-purple w3-round w3-hover-opacity">OpenReview</span></button></a>
            <br>
            <!--
            <p><i class="fa fa-university fa-fw w3-margin-right w3-large w3-text-purple"></i>University of Pennsylvania</p>
            <p><i class="fa fa-home fa-fw w3-margin-right w3-large w3-text-purple"></i>Shenzhen, China</p>-->
            <p><i class="fa fa-envelope fa-fw w3-margin-right w3-large w3-text-purple"></i>zharry@seas.upenn.edu</p>
            <hr>
            <p class="w3-large w3-text-theme"><b><i class="fa fa-suitcase fa-fw w3-margin-right w3-text-purple"></i>Work Experience</b></p>
            <div class="w3-container">
              <h5 class="w3-text-black">Research Intern<img src="image/ibm-logo.05dc870.png" alt="IBM Research" style="float:right;height:20px;"></h5>
              <h6 class="w3-text-purple"><i class="fa fa-calendar fa-fw w3-margin-right"></i>2019, 2021</h6>
              <!--<p>I did NLP research and software development on semantic role labeling, and previously, text simplification.</p>-->
              <hr> </div>
            <div class="w3-container">
              <h5 class="w3-text-black">Teaching Assistant<img src="image/UM-Penn.png" alt="UM-Penn" style="float:right;width:107px;height:50x;"></h5>
              <h6 class="w3-text-purple"><i class="fa fa-calendar fa-fw w3-margin-right"></i>2016 - 2020</h6>
              <!--<p> At Penn, I instructed CIS 530: Computational Linguistics (Winter, Fall 2020). At Michigan, I instructed EECS 595: Natural Language Processing (Fall 2018) and EECS 280: Programming and Introductory Data Structures (Winter, Fall 2016).</p>-->
              <hr> </div>
            <div class="w3-container">
              <h5 class="w3-text-black">Summer Analyst in Technology<img src="image/GoldmanSachsLogo.jpg" alt="Goldman Sachs" style="float:right;height:40px;"></h5>
              <h6 class="w3-text-purple"><i class="fa fa-calendar fa-fw w3-margin-right"></i>2017</h6>
              <!--<p>I performed software engineering, data analytics and machine learning.</p>-->
              <br> </div>
            <p class="w3-large w3-text-theme"><b><i class="fa fa-book fa-fw w3-margin-right w3-text-purple"></i>Education</b></p>
            <div class="w3-container">
              <h5 class="w3-text-black">University of Pennsylvania<img src="image/upenn-logo.png" alt="upenn logo" style="float:right;width:80px;height:80px;"></h5>
              <h6 class="w3-text-purple"><i class="fa fa-graduation-cap fa-fw w3-margin-right"></i>Ph.D.; GPA: 3.92/4.00; <span class="w3-tag w3-purple w3-round w3-hover-opacity">In progress</span></h6>
              <hr> </div>
            <div class="w3-container">
              <h5 class="w3-text-black">University of Michigan<img src="image/umich-logo.png" alt="umich logo" style="float:right;width:80px;height:80px;"></h5>
              <h6 class="w3-text-purple"><i class="fa fa-graduation-cap fa-fw w3-margin-right"></i>B.S.E.; Class of 2018; GPA: 3.82/4.00</h6>
              <hr> </div>
            <div class="w3-container">
              <h5 class="w3-text-black">Shenzhen Middle School<img src="image/sms-logo.jpg" alt="SMS logo" style="float:right;width:80px;height:80px;"></h5>
              <h6 class="w3-text-purple"><i class="fa fa-graduation-cap fa-fw w3-margin-right"></i>High School Diploma; Class of 2015; GPA: 4.23/4.30</h6>
              <br> </div>
            <hr>
            <p class="w3-large w3-text-theme"><b><i class="fas fa-scroll fa-fw w3-margin-right w3-text-purple"></i>Service</b></p>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Reviewer of <a href='https://coling2022.org/coling'  target="_blank">COLING 2022</a> </h6>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Reviewer of <a href='https://openreview.net/group?id=aclweb.org/ACL/ARR'  target="_blank">ARR</a> since October 2021</h6>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Reviewer of <a href='https://lrec2022.lrec-conf.org/en/'  target="_blank">LREC 2022</a> </h6>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Session chair of <a href='http://www.aacl2020.org/'  target="_blank">AACL-IJCNLP 2020</a> </h6>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Co-organizer of <a href='https://nlp.cis.upenn.edu/clunch.html'  target="_blank">CLUNCH</a> in 2020, Penn's NLP seminar series </h6>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Reviewer of <a href='https://coling2020.org/'  target="_blank">COLING 2020</a> </h6>
            <h6 class="w3-text-black"><i class="fa fa-pen-nib fa-fw w3-margin-right"></i>Reviewer of <a href='https://www.journals.elsevier.com/computer-speech-and-language'  target="_blank">Computer Speech and Language</a> 2018</h6>
            


            <!--
            <p class="w3-large w3-text-theme"><b><i class="fas fa-headphones fa-fw w3-margin-right w3-text-purple"></i>Music</b></p>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/playlist?list=PLdoWMpbmbJL_qDspGQtEgAMj9iHam6qqh" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
            <p>ACG music rearranged and remade as metal or rock</p>
            <br>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/playlist?list=PLdoWMpbmbJL_1uPoMssP9YU7jqPPg3-5V" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
            <p>ACG music rearranged and remade as jazz, fusion or funk</p>
            <br>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/playlist?list=PLdoWMpbmbJL8eOIbK7jdJyIJwz46JLiuw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
            <p>Metal music covers</p>
            <br>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/playlist?list=PLdoWMpbmbJL-6JgN_t7txxRDK__eXDG1-" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
            <p>Drum covers</p>
            <br>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/playlist?list=PLdoWMpbmbJL8_nyDb9qQW3P6eO6s1xVJH" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
            <p>Guitar and bass covers</p>
            
            <br>
            <p class="w3-large w3-text-theme"><b><i class="fa fa-bullseye fa-fw w3-margin-right w3-text-purple"></i>Pool</b></p>
            <div class="video-container">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/playlist?list=PLdoWMpbmbJL9mkYJpyqxAcs2f3F32sGUi" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
            <p>I used to play pool competitively. I was in the university team and played in intercollegiate tournaments regularly.</p>
            --><br> </div>
        </div>
        <br>
        <!-- End Left Column -->
      </div>
      <!-- Right Column -->
      <div class="w3-twothird">
        <div class="w3-container w3-card-2 w3-white w3-margin-bottom">
          <h2 class="w3-text-grey w3-padding-16"><i class="fa fa-glasses fa-fw w3-margin-right w3-xxlarge w3-text-purple"></i>Research</h2>
          <div class="w3-container">
            <a name="pub6"></a>
            <h5 class="w3-text-gray"><b>[6] Reasoning about Goals, Steps, and Temporal Ordering with WikiHow</b></h5>
            <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b><span class="tooltip">*<span class="tooltiptext">Equal contribution</span></span>, Qing Lyu<span class="tooltip">*<span class="tooltiptext">Equal contribution</span></span> and Chris Callison-Burch</h6>
            <p><a href="https://www.aclweb.org/anthology/2020.emnlp-main.374/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('emnlp2020-1bib')">BibTeX</span> <a href="https://github.com/zharry29/wikihow-goal-step" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> &nbsp;In <a href="https://2020.emnlp.org/" target="_blank">EMNLP 2020</a>; presented at <a href="https://welmworkshop.github.io/" target="_blank">Workshop on Enormous Language Models</a> at ICLR 2021; a part of the <a href="https://github.com/google/BIG-bench" target="_blank">Beyond the Imitation Game Benchmark (BIG-bench)</a>.</p>
            <div id="emnlp2020-1bib" class='hidden'> <pre style="overflow:auto">
@inproceedings{zhang-etal-2020-reasoning,
  title = "Reasoning about Goals, Steps, and Temporal Ordering with {W}iki{H}ow",
  author = "Zhang, Li  and
    Lyu, Qing  and
    Callison-Burch, Chris",
  booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
  month = nov,
  year = "2020",
  address = "Online",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/2020.emnlp-main.374",
  pages = "4630--4639",
}
          </pre> </div> </div>
          <div class="w3-container">
            <a name="pub7"></a>
            <h5 class="w3-text-gray"><b>[7] Intent Detection with WikiHow</b></h5>
            <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b>, Qing Lyu and Chris Callison-Burch</h6>
            <p><a href="https://www.aclweb.org/anthology/2020.aacl-main.35/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('aacl2020bib')">BibTeX</span> <a href="https://github.com/zharry29/wikihow-intent" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> &nbsp;In <a href="http://www.aacl2020.org/" target="_blank">AACL-IJCNLP 2020</a>.</p>
            <div id="aacl2020bib" class='hidden'> <pre style="overflow:auto">
@inproceedings{zhang-etal-2020-intent,
  title = "Intent Detection with {W}iki{H}ow",
  author = "Zhang, Li  and
    Lyu, Qing  and
    Callison-Burch, Chris",
  booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
  month = dec,
  year = "2020",
  address = "Suzhou, China",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/2020.aacl-main.35",
  pages = "328--333",
  abstract = "Modern task-oriented dialog systems need to reliably understand users{'} intents. Intent detection is even more challenging when moving to new domains or new languages, since there is little annotated data. To address this challenge, we present a suite of pretrained intent detection models which can predict a broad range of intended goals from many actions because they are trained on wikiHow, a comprehensive instructional website. Our models achieve state-of-the-art results on the Snips dataset, the Schema-Guided Dialogue dataset, and all 3 languages of the Facebook multilingual dialog datasets. Our models also demonstrate strong zero- and few-shot performance, reaching over 75{\%} accuracy using only 100 training examples in all datasets.",
}
          </pre> </div> 
          <p>
            Our first effort is to <b>extract</b> the procedural events. For example, to "record music" you need to "buy suitable equipments"; such is a goal-step relation. But before you "buy suitable equipments", you should "plan out your budget"; such is a step-step temporal relation. We use wikiHow to build datasets to train and test models that can <b>reason </b> about such relations. Our models show strong zero- and few-shot results on other tasks, especially on intent detection in dialogs.
          </p>
          <hr>
        </div>
        
        <div class="w3-container">
          <a name="pub8"></a>
          <h5 class="w3-text-gray"><b>[8] Goal-Oriented Script Construction</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Qing Lyu<span class="tooltip">*<span class="tooltiptext">Equal contribution</span></span>, <b>Li Zhang</b><span class="tooltip">*<span class="tooltiptext">Equal contribution</span></span> and Chris Callison-Burch</h6>
          <p><a href="https://aclanthology.org/2021.inlg-1.19/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('inlg2021bib')">BibTeX</span> <a href="https://github.com/veronica320/wikihow-GOSC" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> In <a href="https://inlg2021.github.io/index.html" target="_blank">INLG 2021</a>.</p>
                       <div id="inlg2021bib" class='hidden'> <pre style="overflow:auto">
@inproceedings{lyu-etal-2021-goal,
title = "Goal-Oriented Script Construction",
author = "Lyu, Qing  and
  Zhang, Li  and
  Callison-Burch, Chris",
booktitle = "Proceedings of the 14th International Conference on Natural Language Generation",
month = aug,
year = "2021",
address = "Aberdeen, Scotland, UK",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2021.inlg-1.19",
pages = "184--200",
abstract = "The knowledge of scripts, common chains of events in stereotypical scenarios, is a valuable asset for task-oriented natural language understanding systems. We propose the Goal-Oriented Script Construction task, where a model produces a sequence of steps to accomplish a given goal. We pilot our task on the first multilingual script learning dataset supporting 18 languages collected from wikiHow, a website containing half a million how-to articles. For baselines, we consider both a generation-based approach using a language model and a retrieval-based approach by first retrieving the relevant steps from a large candidate pool and then ordering them. We show that our task is practical, feasible but challenging for state-of-the-art Transformer models, and that our methods can be readily deployed for various other datasets and domains with decent zero-shot performance.",
}
        </pre> </div>
          <p>
          One of the holy-grails of procedural knowledge is for models to <b>construct</b> complete, high-quality procedures from scratch. We push the limit of our models and explore this difficult task in 18 languages, using techniques in both information retrieval and generation by language models. The task turns out extremely challenging, but not impossible.
        </p> <hr></div>
        <div class="w3-container">
          <a name="pub10"></a>
          <h5 class="w3-text-gray"><b>[10] Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Shuyan Zhou<span class="tooltip">*<span class="tooltiptext">Equal contribution</span></span>, <b>Li Zhang</b><span class="tooltip">*<span class="tooltiptext">Equal contribution</span></span>, Yue Yang, Qing Lyu, Pengcheng Yin, Chris Callison-Burch and Graham Neubig</h6>
          <p><a href="https://aclanthology.org/2022.acl-long.214/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('hierarchybib')">BibTeX</span> <a href="https://wikihow-hierarchy.github.io/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Demo</span></a> <a href="https://www.2022.aclweb.org/" target="_blank">In ACL 2022.</a></p>
          <div id="hierarchybib" class='hidden'> 
            <pre style="overflow:auto">
@inproceedings{zhou-etal-2022-show,
title = "Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data",
author = "Zhou, Shuyan  and
    Zhang, Li  and
    Yang, Yue  and
    Lyu, Qing  and
    Yin, Pengcheng  and
    Callison-Burch, Chris  and
    Neubig, Graham",
booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
month = may,
year = "2022",
address = "Dublin, Ireland",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2022.acl-long.214",
pages = "2998--3012",
abstract = "Procedures are inherently hierarchical. To {``}make videos{''}, one may need to {``}purchase a camera{''}, which in turn may require one to {``}set a budget{''}. While such hierarchical knowledge is critical for reasoning about complex procedures, most existing work has treated procedures as shallow structures without modeling the parent-child relation. In this work, we attempt to construct an open-domain hierarchical knowledge-base (KB) of procedures based on wikiHow, a website containing more than 110k instructional articles, each documenting the steps to carry out a complex procedure. To this end, we develop a simple and efficient method that links steps (e.g., {``}purchase a camera{''}) in an article to other articles with similar goals (e.g., {``}how to choose a camera{''}), recursively constructing the KB. Our method significantly outperforms several strong baselines according to automatic evaluation, human judgment, and application to downstream tasks such as instructional video retrieval.",
}
        </pre> 
      </div> 
   
        <p>
          While all our previous work has treated procedures as a flat structure, procedural events are inherently <b>hierarchical</b>. To "become a great musician", you need to "practice", which in turn requires "making effective plans". We constructed an event hierarchy from wikiHow and showed that it efficiently aided users perform daily tasks and improved performance of downstream tasks such as video retrieval.
        </p> <hr></div>
        <div class="w3-container">
          <a name="pub10"></a>
          <h5 class="w3-text-gray"><b>[14] QuakerBot: A Household Dialog System Powered by Large Language Models</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Artemis Panagopoulou, Manni Arora, <b>Li Zhang</b>, (9 more), Chris Callison-Burch, Mark Yatskar</h6>
          <p><a href="TODO" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('quakerbotbib')">BibTeX</span> <a href="TODO" target="_blank">To be published.</a></p>
          <div id="quakerbotbib" class='hidden'> 
            <pre style="overflow:auto">
@TODO
        </pre> 
      </div> 
   
      <p>
        To show the power of our datasets and models, I co-led University of Pennsylvania's effort to participate in the <a href='https://www.amazon.science/alexa-prize/teams/university-of-pennsylvania-quakerbot' target="_blank">Alexa Prize TaskBot challenge</a>, where we build a <b>dialog system</b> to help users do household tasks. 
      </p> </div>            <div id='show_more_button'>
        <button onclick="toggleMoreResearch()" class='button'><span class="w3-tag w3-purple w3-round w3-hover-opacity">See more research projects</span></button>
      </div>
      <div id="more_research" class='hidden'>
        <div class="w3-container">
          <hr>
          <a name="pub15"></a>
          <h5 class="w3-text-gray"><b>[15] Reasoning about Procedures with Natural Language Processing: A Tutorial</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b></h6>
          <p><a href="https://arxiv.org/abs/2205.07455" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('wpe2bib')">BibTeX</span> In arXiv.</p>
          <div id="wpe2bib" class='hidden'> <pre style="overflow:auto">
@misc{https://doi.org/10.48550/arxiv.2205.07455,
  doi = {10.48550/ARXIV.2205.07455},
  url = {https://arxiv.org/abs/2205.07455},
  author = {Zhang, Li},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Reasoning about Procedures with Natural Language Processing: A Tutorial},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
        </pre> </div>
          <p>
            I wrote a tutorial on reasoning about procedures.
          </p><hr>
        </div>
        <div class="w3-container">
          <a name="pub9"></a>
          <h5 class="w3-text-gray"><b>[9] Visual Goal-Step Inference using wikiHow</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Yue Yang, Artemis Panagopoulou, Qing Lyu, <b>Li Zhang</b>, Mark Yatskar and Chris Callison-Burch</h6>
          <p><a href="https://aclanthology.org/2021.emnlp-main.165/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('emnlp2021bib')">BibTeX</span> In <a href="https://2021.emnlp.org/" target="_blank">EMNLP 2021</a>; presented at the <a href="https://alvr-workshop.github.io/" target="_blank">2nd Workshop on Advances in Language and Vision Research</a> at <a href="https://2021.naacl.org/" target="_blank">NAACL 2021</a>.</p>
          <div id="emnlp2021bib" class='hidden'> <pre style="overflow:auto">
@inproceedings{yang-etal-2021-visual,
title = "Visual Goal-Step Inference using wiki{H}ow",
author = "Yang, Yue  and
  Panagopoulou, Artemis  and
  Lyu, Qing  and
  Zhang, Li  and
  Yatskar, Mark  and
  Callison-Burch, Chris",
booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
month = nov,
year = "2021",
address = "Online and Punta Cana, Dominican Republic",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2021.emnlp-main.165",
pages = "2167--2179",
abstract = "Understanding what sequence of steps are needed to complete a goal can help artificial intelligence systems reason about human activities. Past work in NLP has examined the task of goal-step inference for text. We introduce the visual analogue. We propose the Visual Goal-Step Inference (VGSI) task, where a model is given a textual goal and must choose which of four images represents a plausible step towards that goal. With a new dataset harvested from wikiHow consisting of 772,277 images representing human actions, we show that our task is challenging for state-of-the-art multimodal models. Moreover, the multimodal representation learned from our data can be effectively transferred to other datasets like HowTo100m, increasing the VGSI accuracy by 15 - 20{\%}. Our task will facilitate multimodal reasoning about procedural events.",
}
        </pre> </div>
          <p>
            The inference of goal-step relations does not have to be confined to texts. Images and videos can also represent procedural events, with potentially richer information. We extend our task to a <b>multimodal</b> setting, showing the potential to generalize from the visuals in wikiHow to other domains.
          </p><hr>
        </div>
        <div class="w3-container">
            <a name="pub11"></a>
            <h5 class="w3-text-gray"><b>[11] Label Definitions Improve Semantic Role Labeling</b></h5>
            <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b>, Ishan Jindal, Yunyao Li</h6>
            <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('srlbib')">BibTeX</span> <a href="https://github.com/System-T/LabelAwareSRL" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> In <a href="https://2022.naacl.org/" target="_blank">NAACL 2022</a>.</p>
            <div id="srlbib" class='hidden'> <pre style="overflow:auto">
@inproceedings{zhang-etal-2022-label,
  title = "Label Definitions Improve Semantic Role Labeling",
  author = "Zhang, Li and
   Jindal, Ishan and
   Li, Yunyao",
  booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month = july,
  year = "2022",
  address = "Seattle, USA",
  publisher = "Association for Computational Linguistics"
}
          </pre> </div> 
        <p>Semantic role labeling answers the question of "who did what to whom, when and how", extracting important information about a predicate. While previous work has treated the semantic role labels as symbolic, we explicitly use their definitions and advance state-of-the-art with some limitations. </p>
        <hr> </div>
        <div class="w3-container">
          <a name="pub12"></a>
          <h5 class="w3-text-gray"><b>[12] Is "my favorite new movie" my favorite movie? Probing the Understanding of Recursive Noun Phrases</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Qing Lyu, Hua Zheng, Daoxin Li, <b>Li Zhang</b>, Marianna Apidianaki and Chris Callison-Burch</h6>
          <p><a href="https://arxiv.org/abs/2112.08326" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('npbib')">BibTeX</span> <a href="https://github.com/veronica320/Recursive-NPs" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> In <a href="https://2022.naacl.org/" target="_blank">NAACL 2022</a>.</p>
          <div id="npbib" class='hidden'> <pre style="overflow:auto">
@inproceedings{lyu-etal-2022-favorite,
title = "Is 'my favorite new movie' my favorite movie? Probing the Understanding of Recursive Noun Phrases",
author = "Lyu, Qing and
 Zheng, Hua and
 Li, Daoxin and
 Zhang, Li and
 Apidianaki, Marianna and
 Callison-Burch, Chris",
booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
month = july,
year = "2022",
address = "Seattle, USA",
publisher = "Association for Computational Linguistics"
}
        </pre> </div> 
      <p>Do large language models know that a "favorite new movie" is not necessarily a "new favorite movie"?</p>
      </div>
        <div class="w3-container">
          <a name="pub5"></a>
          <h5 class="w3-text-gray"><b>[5] Small but Mighty: New Benchmarks for Split and Rephrase</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b>, Huaiyu Zhu, Siddhartha Brahma and Yunyao Li</h6>
          <p><a href="https://www.aclweb.org/anthology/2020.emnlp-main.91/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('emnlp2020-2bib')">BibTeX</span> <a href="https://github.com/System-T/TextSimplification" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> &nbsp;In <a href="https://2020.emnlp.org/" target="_blank">EMNLP 2020</a>; a part of the <a href="https://gem-benchmark.com" target="_blank">GEM Benchmark</a>.</p>
          <div id="emnlp2020-2bib" class='hidden'> <pre style="overflow:auto">
@inproceedings{zhang-etal-2020-small,
title = "Small but Mighty: New Benchmarks for Split and Rephrase",
author = "Zhang, Li  and
  Zhu, Huaiyu  and
  Brahma, Siddhartha  and
  Li, Yunyao",
booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
month = nov,
year = "2020",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://www.aclweb.org/anthology/2020.emnlp-main.91",
pages = "1198--1205",
}      
        </pre> </div> Split and Rephrase is a text simplification task to rewrite a complex sentence into several simpler ones. We show that the existing benchmark is too simplistic, developing a rule-based model using no training data which performs on par with the current state-of-the-art neural model. We then propose two new crowdsourced benchmarks with improved quality. We also provide a study on the flaws of BLEU score, and the cost-efficiency of using crowd workers to evaluate models. </p>
        <hr> </div>
        <div class="w3-container">
          <a name="pub4"></a>
          <h5 class="w3-text-gray"><b>[4] Multi-Label Transfer Learning for Multi-Relational Semantic Similarity</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b>, Steven R. Wilson and Rada Mihalcea</h6>
          <p><a href="https://www.aclweb.org/anthology/S19-1005" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('sem2019bib')">BibTeX</span> <a href="docs/starSEM2019-presentation.pdf" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Slides</span></a> &nbsp; In <a href="https://starsem.org/2019/" target="_blank">*SEM 2019</a>.</p>
          <div id="sem2019bib" class='hidden'> <pre style="overflow:auto">
@inproceedings{zhang-etal-2019-multi,
title = "Multi-Label Transfer Learning for Multi-Relational Semantic Similarity",
author = "Zhang, Li  and
  Wilson, Steven  and
  Mihalcea, Rada",
booktitle = "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019)",
month = jun,
year = "2019",
address = "Minneapolis, Minnesota",
publisher = "Association for Computational Linguistics",
url = "https://www.aclweb.org/anthology/S19-1005",
pages = "44--50",
abstract = "Multi-relational semantic similarity datasets define the semantic relations between two short texts in multiple ways, e.g., similarity, relatedness, and so on. Yet, all the systems to date designed to capture such relations target one relation at a time. We propose a multi-label transfer learning approach based on LSTM to make predictions for several relations simultaneously and aggregate the losses to update the parameters. This multi-label regression approach jointly learns the information provided by the multiple relations, rather than treating them as separate tasks. Not only does this approach outperform the single-task approach and the traditional multi-task learning approach, but it also achieves state-of-the-art performance on all but one relation of the Human Activity Phrase dataset.",
}
        </pre> </div> </div>
        <div class="w3-container">
          <a name="pub3"></a>
          <h5 class="w3-text-gray"><b>[3] Direct Network Transfer: Transfer Learning of Sentence Embeddings for Semantic Similarity</b></h5>
          <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i><b>Li Zhang</b>, Steven R. Wilson and Rada Mihalcea</h6>
          <p><a href="https://arxiv.org/abs/1804.07835" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('dntbib')">BibTeX</span> <a href="docs/ic2s2_18_activities.pptx.pdf"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Poster</span></a> &nbsp; In arXiv pre-print; presented at <a href="https://www.kellogg.northwestern.edu/news-events/conference/ic2s2/2018.aspx" target='_blank'>IC2S2 2018</a>.</p>
          <div id="dntbib" class='hidden'> <pre style="overflow:auto">
@misc{zhang2018direct,
title={Direct Network Transfer: Transfer Learning of Sentence Embeddings for Semantic Similarity},
author={Li Zhang and Steven R. Wilson and Rada Mihalcea},
year={2018},
eprint={1804.07835},
archivePrefix={arXiv},
primaryClass={cs.CL}
}
        </pre> </div>
        Recent advancement on neural sentence embeddings show highly competitive performance on semantic similarity tasks. However, the embeddings don't usually just work off-the-shelf, as we show that the transfer learning methodology is crucial to performance. We propose a fine-tuning approach and a multi-label approach which outperforms most alternative transfer learning approaches on semantic similarity tasks, achieving state-of-the-art performance on multiple datasets. </p>
          <hr> </div>
        <div class="w3-container">
          <h5 class="w3-text-gray"><b>Crosslingual Information Retrieval</b> </h5>
          <h6 class="w3-text-purple"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Sept 2019 - April 2021</h6> This work is a part of the <a href='https://www.iarpa.gov/index.php/research-programs/better' target="_blank">IARPA BETTER project</a>. Given training data of event and entity extraction in one language, the goal is to to transfer to another language without training data. We consider zero-shot transfer and some translation-based baselines.
          <hr> </div>
          <div class="w3-container">
            <a name="pub1"></a>
            <h5 class="w3-text-gray"><b>[1] Improving Text-to-SQL Evaluation Methodology</b></h5>
            <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Catherine Finegan-Dollak, Jonathan K. Kummerfeld,
         <b>Li Zhang</b>, Karthik Ramanathan Dhanalakshmi
         Ramanathan, Sesh Sadasivam, Rui Zhang and Dragomir
         Radev</h6>
            <p><a href="https://www.aclweb.org/anthology/P18-1033/" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('acl2018bib')">BibTeX</span> <a href="https://github.com/jkkummerfeld/text2sql-data"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Repo</span></a> <a href="docs/acl2018_poster - final.pdf"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Poster</span></a> &nbsp; In <a href='https://acl2018.org/' target="_blank">ACL 2018</a>.</p>
            <div id="acl2018bib" class='hidden'> <pre style="overflow:auto">
@InProceedings{acl18sql,
  author    = {Catherine Finegan-Dollak\*  and  Jonathan K. Kummerfeld\*  and  Li Zhang  and  Karthik Ramanathan  and  Sesh Sadasivam  and  Rui Zhang  and  Dragomir Radev},
  title     = {Improving Text-to-SQL Evaluation Methodology},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  shortvenue = {ACL},
  month     = {July},
  year      = {2018},
  address   = {Melbourne, Victoria, Australia},
  pages     = {351--360},
  abstract  = {To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.},
  url       = {http://aclweb.org/anthology/P18-1033},
  software  = {https://github.com/jkkummerfeld/text2sql-data},
  data      = {https://github.com/jkkummerfeld/text2sql-data},
}
          </pre> </div>
          This work is a part of the <a href='http://sapphire.eecs.umich.edu/' target="_blank">UM-IBM Sapphire project</a>. The goal is to build a dialog system able to answer questions about university course information. While tackling the task of translating natural language to SQL, we identified flaws in the current text-to-SQL evaluation scheme and proposed alternatives. I contributed to building the a text-to-SQL dataset and implementing named entitiy recognition as a preprocessing step.</p>
          <hr> </div>
          <div class="w3-container">
            <a name="pub2"></a>
            <h5 class="w3-text-gray"><b>[2] Entity and Event Extraction from Scratch Using Minimal Training Data</b></h5>
            <h6 class="w3-text-black"><i class="fa fa-users fa-fw w3-margin-right"></i>Laura Burdick, Steven R. Wilson, Oana Ignat, Charles F. Welch, <b>Li Zhang</b>, Mingzhe Wang, Jia Deng and Rada Mihalcea</h6>
            <p><a href="https://tac.nist.gov/publications/2018/participant.papers/TAC2018.Michigan.proceedings.pdf" target="_blank"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Paper</span></a> <span class="help w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity" onclick="toggle('tac2018bib')">BibTeX</span> <a href="docs/ic2s2_18_activities.pptx.pdf"><span class="w3-tag w3-white w3-border w3-border-black w3-text-black w3-round w3-hover-opacity">Poster</span></a> &nbsp; In <a href="http://www.tac.mta.ca/tac/" target="_blank">TAC 2018.</p>
            <div id="tac2018bib" class='hidden'> <pre style="overflow:auto">
@article{Burdick2018EntityAE,
title={Entity and Event Extraction from Scratch Using Minimal Training Data},
author={Laura Burdick and Steven R. Wilson and Oana Ignat and Charles F Welch and Li Zhang and Mingzhe Wang and Jia Deng and Rada Mihalcea},
journal={Theory and Applications of Categories},
year={2018}
}
          </pre> </div>
          <p>This work is a part of the <a href='https://www.darpa.mil/program/active-interpretation-of-disparate-alternatives' target="_blank">DARPA AIDA project</a>. From the texts, audios and videos recounting the Russia-Ukraine conflict in 2014, the goal is to extract knowledge elements and generate hypotheses about real-life events. I used named entity recognition, keyword extraction and word embeddings to extract textual entities from the data and assign them with categories from the given ontology.</p>
          <hr> </div>
        <div class="w3-container">
          <h5 class="w3-text-gray"><b>Cartoon Caption Clustering</b><span style="float:right;"><a href="http://tangra.cs.yale.edu//cartoons/newFold/cartoongallery2.php" target="_blank"><i class="fa fa-globe w3-xlarge w3-hover-opacity"></i></a></span></h5>
          <h6 class="w3-text-purple"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Jan 2016 - Apr 2016 </h6>
          <p>In each volume of the New Yorker magazine, there is a comic section where thousands of readers submit funny captions. The goal is to automatically divide them into clusters based on their theme of humor (what they are joking about) using unsupervised learning. Work had been done years ago but the codes were scattered and underdocumented. I as a freshman was in charge of this project, to bring the existing system up to date and to make optimization. </p>
          <hr> </div>
        <div class="w3-container">
          <h5 class="w3-text-gray"><b>ACL Anthology Network</b><span style="float:right;"><a href="http://tangra.cs.yale.edu/newaan/" target="_blank"><i class="fa fa-globe w3-xlarge w3-hover-opacity"></i></a></span></h5>
          <!-- <img src="image/1200px-Association_for_Computational_Linguistics_logo.svg.png" alt="ACL" height="50" width="75"> -->
          <h6 class="w3-text-purple"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Sept 2016 - Dec 2016 </h6>
          <p>AAN encompases our corpus of resources on NLP and related fields and the research projects which build upon this corpus. We have collected around 6,500 surveys, tutorials and other resources and created a search engine which allows users to easily browse these resources. I helped build and maintain this power anthology with information regarding numerous papers included in top NLP venues. It features paper citation, author citation, and author collaboration, etc. </p>
        </div>
      </div>
      <div id='show_less_button' class='hidden'>
        <hr>
        <button onclick="toggleCollapseResearch()" class='button'><span class="w3-tag w3-purple w3-round w3-hover-opacity">Collapse</span></button>
      </div>
      <br> 
          </div>
        
          <div class="w3-container w3-card-2 w3-white w3-margin-bottom">
            <h2 class="w3-text-grey w3-padding-16"><i class="fa fa-headphones fa-fw w3-margin-right w3-xxlarge w3-text-purple"></i>Music</h2>
            <p>I play, record and produce music regularly. I enjoy genres ranging from progressive metal to pop to jazz. I'm passionate about rearranging and recreating soundtracks from video games and animes (ACG). I take pride in my 10k-subscriber channel on <a href="https://space.bilibili.com/483770554" target="_blank">Bilibili</a>. My music can be found on all major streaming platforms and <a href="https://www.youtube.com/c/HazStudio" target="_blank">YouTube</a>. 
  
                <div style="position: relative; padding: 30% 45%"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0" src="https://player.bilibili.com/player.html?aid=383827185&bvid=BV1qZ4y1h7ej&cid=714737715;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;as_wide=1" frameborder="no" scrolling="no" width="320" height="240"></iframe></div>
                <br>
  
                <div style="position: relative; padding: 30% 45%"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0" src="https://player.bilibili.com/player.html?aid=896292746&bvid=BV11A4y1U7NW&cid=711517517;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;as_wide=1" frameborder="no" scrolling="no" width="320" height="240"></iframe></div>
                <br>
  
                <div style="position: relative; padding: 30% 45%"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0" src="https://player.bilibili.com/player.html?aid=636584793&bvid=BV1hb4y147Rs&cid=509972902;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;as_wide=1" frameborder="no" scrolling="no" width="320" height="240"></iframe></div>
                <br>
  
                <div style="position: relative; padding: 30% 45%"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0" src="https://player.bilibili.com/player.html?aid=852454260&bvid=BV1xL4y1M78u&cid=555991614;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;as_wide=1" frameborder="no" scrolling="no" width="320" height="240"></iframe></div>
                <br>
  
                <div style="position: relative; padding: 30% 45%"><iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0" src="https://player.bilibili.com/player.html?aid=254602264&bvid=BV1kY411g7Wf&cid=542782784;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;as_wide=1" frameborder="no" scrolling="no" width="320" height="240"></iframe></div>
          </div>
          <!-- End Right Column -->
      </div>
      <!-- End Grid -->
    </div>
    <!-- End Page Container -->
  </div>
  <footer class="w3-container w3-purple w3-center w3-margin-top">
    <p>&copy; Li Zhang 2022 &middot; All rights reserved &middot; Powered by w3.css</p>
  </footer>
</body>

</html>